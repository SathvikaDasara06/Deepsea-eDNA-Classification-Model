# -*- coding: utf-8 -*-
"""FinalSIHeDNAModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bb_-STZlvr2UOSaZXqPbXaI3KGVOZNle
"""

!pip install biopython tqdm tensorflow scikit-learn pandas hdbscan

import numpy as np
import pandas as pd
from Bio import SeqIO
from google.colab import files
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input
from tensorflow.keras.utils import to_categorical

class CGR:
    def __init__(self, seq):
        self.seq = seq.upper()
    def representation(self):
        coordinates = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])
        residues = ["A", "C", "T", "G"]
        sequence = [[coordinates.mean(axis=0)[0], coordinates.mean(axis=0)[1]]]
        for base in self.seq:
            if base not in residues: continue
            pos = 0.5 * (np.array(sequence[-1]) + coordinates[residues.index(base)])
            sequence.append(list(pos))
        return np.array(sequence)
    def rasterize(self, grid_size=64):
        r = self.representation()
        grid_x = np.clip(((r[:,0]+1)/2*(grid_size-1)).round().astype(int), 0, grid_size-1)
        grid_y = np.clip(((r[:,1]+1)/2*(grid_size-1)).round().astype(int), 0, grid_size-1)
        grid = np.zeros((grid_size,grid_size),dtype=int)
        for x, y in zip(grid_x,grid_y): grid[y,x] += 1
        return grid

def parse_species_id(seq_id):
    parts = seq_id.replace('>', '').strip().split()
    if len(parts) >= 3:
        return parts[1] + " " + parts[2]
    elif len(parts) >= 2:
        return parts[1]
    else:
        return parts[0]

print("Upload labeled FASTA file (header=species):")
uploaded_train = files.upload()
fasta_train_file = list(uploaded_train.keys())[0]
train_records = list(SeqIO.parse(fasta_train_file, "fasta"))
train_records = train_records[:5000]
species_labels = [parse_species_id(rec.id) for rec in train_records]
species_to_int = {sp:i for i,sp in enumerate(sorted(set(species_labels)))}
int_labels = np.array([species_to_int[sp] for sp in species_labels])
raster_images = np.array([CGR(str(rec.seq)).rasterize(grid_size=64) for rec in train_records])[..., np.newaxis]
num_classes = len(species_to_int)

Y = to_categorical(int_labels, num_classes=num_classes)

model = Sequential([
    Input(shape=(64, 64, 1)),
    Conv2D(16, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(name='feat_flatten'),
    Dense(64, activation='relu', name='feat_dense'),
    Dense(num_classes, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(raster_images, Y, epochs=30, batch_size=32)
model.save('cgr_species_cnn.h5')
print("Model trained and saved!")

!pip install biopython tqdm tensorflow scikit-learn pandas hdbscan

import numpy as np
import pandas as pd
from tqdm import tqdm
from tensorflow.keras.models import load_model
import hdbscan

class CGR:
    def __init__(self, seq):
        self.seq = seq.upper()
    def representation(self):
        coordinates = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])
        residues = ["A", "C", "T", "G"]
        sequence = [coordinates.mean(axis=0).tolist()]
        for base in self.seq:
            if base not in residues: continue
            pos = 0.5 * (np.array(sequence[-1]) + coordinates[residues.index(base)])
            sequence.append(list(pos))
        return np.array(sequence)
    def rasterize(self, grid_size=64):
        r = self.representation()
        grid_x = np.clip(((r[:,0]+1)/2*(grid_size-1)).round().astype(int), 0, grid_size-1)
        grid_y = np.clip(((r[:,1]+1)/2*(grid_size-1)).round().astype(int), 0, grid_size-1)
        grid = np.zeros((grid_size, grid_size), dtype=int)
        for x, y in zip(grid_x, grid_y): grid[y,x] += 1
        return grid

def get_windows(seq, win_len=120, step=60):
    seq = seq.strip().replace("\n", "")
    return [seq[i:i+win_len] for i in range(0, len(seq)-win_len+1, step) if set(seq[i:i+win_len]) <= set("ACTGactg")]

print("Upload your raw DNA file (continuous, no headers):")
from google.colab import files
uploaded = files.upload()
raw_seq_file = list(uploaded.keys())[0]
with open(raw_seq_file) as f:
    sequence = "".join([line.strip() for line in f if set(line.strip()) <= set("ACTGactg")])

windows = get_windows(sequence, win_len=120, step=60)
print(f"Windows generated: {len(windows)}")

cgr_rasters = np.array([CGR(seq).rasterize(64) for seq in tqdm(windows)])[:, :, :, np.newaxis].astype('float32')

model = load_model('cgr_species_cnn.h5')

layer_outputs = []
x = cgr_rasters
for layer in model.layers:
    x = layer(x)
    layer_outputs.append(x)
feature_vectors = layer_outputs[-2].numpy()

clusterer = hdbscan.HDBSCAN(min_cluster_size=5)
cluster_labels = clusterer.fit_predict(feature_vectors)
cnn_preds = np.argmax(layer_outputs[-1].numpy(), axis=1)

results_df = pd.DataFrame({
    "Window_Start": [i for i in range(0, len(sequence)-120+1, 60)],
    "Window_Sequence": windows,
    "Cluster": cluster_labels,
    "CNN_Predicted_Label": cnn_preds
})

abundance_df = pd.Series(cnn_preds).value_counts().reset_index()
abundance_df.columns = ['Predicted_Label', 'Abundance']

results_df.to_csv("windows_cgr_clusters_cnn_labels.csv", index=False)
abundance_df.to_csv("species_abundance_summary.csv", index=False)

print("windows_cgr_clusters_cnn_labels.csv and species_abundance_summary.csv saved.")

from google.colab import files
files.download('windows_cgr_clusters_cnn_labels.csv')